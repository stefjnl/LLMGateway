# US-003: Application Layer Implementation

---

## User Story

**As a** developer  
**I want to** implement the Application layer with orchestration, plugins, and DTOs  
**So that** I have a working business logic layer that coordinates domain entities and prepares for Infrastructure integration

---

## Acceptance Criteria

### ✅ Criterion 1: DTOs Defined
- [ ] `ChatRequest` DTO with Messages, Model, Temperature, MaxTokens properties
- [ ] `ChatResponse` DTO with Content, Model, TokensUsed, EstimatedCost, ResponseTime properties
- [ ] `Message` DTO with Role and Content properties
- [ ] All DTOs use proper nullable annotations
- [ ] DTOs are serializable (public properties, parameterless constructor)

### ✅ Criterion 2: Command Implemented
- [ ] `SendChatCompletionCommand` record with validation method
- [ ] `Validate()` checks: messages not empty, temperature 0-2, maxTokens positive
- [ ] Throws `ArgumentException` with descriptive messages on validation failure

### ✅ Criterion 3: ModelSelectionPlugin Implemented
- [ ] `[KernelFunction("select_model")]` decoration
- [ ] Implements 3-rule logic from ADR-003:
  - Rule 1: User override (if userModel provided, return it)
  - Rule 2: Large context (if tokenCount > 10,000, return Kimi-K2)
  - Rule 3: Default (return glm-4.6)
- [ ] Throws `TokenLimitExceededException` if tokenCount > 200,000
- [ ] Returns ModelName value object (not string)

### ✅ Criterion 4: ProviderFallbackPlugin Implemented
- [ ] `[KernelFunction("get_fallback_model")]` decoration
- [ ] Implements circular fallback chain: glm-4.6 → DeepSeek → Kimi-K2
- [ ] Throws `AllProvidersFailedException` if cycle detected (attempted all 3 models)
- [ ] Takes failed model as input, returns next model in chain

### ✅ Criterion 5: CostTrackingPlugin Implemented
- [ ] `[KernelFunction("track_cost")]` decoration
- [ ] Constructor-injected: IRequestLogRepository, IModelPricingRepository, ILogger
- [ ] Fetches ModelPricing from repository by model name
- [ ] Calculates cost using `pricing.CalculateCost(inputTokens, outputTokens)`
- [ ] Creates RequestLog entity via factory method
- [ ] Persists log via repository
- [ ] Handles missing pricing gracefully (logs warning, uses zero cost)

### ✅ Criterion 6: KernelFactory Implemented
- [ ] Constructor-injected: IServiceProvider
- [ ] `CreateWithPlugins()` method returns configured Kernel
- [ ] Pulls `IChatCompletionService` from DI
- [ ] Registers all 3 plugins via `AddFromObject()` with DI-resolved instances
- [ ] Plugin names: "ModelSelection", "CostTracking", "ProviderFallback"

### ✅ Criterion 7: KernelOrchestrator Implemented
- [ ] Constructor-injected: KernelFactory, all 3 plugins, ILogger
- [ ] `SendChatCompletionAsync(command, ct)` method implements full flow:
  1. Estimate tokens from messages
  2. Call ModelSelectionPlugin to select model
  3. Build ChatHistory from messages
  4. Get IChatCompletionService from Kernel
  5. Call completion service with retry loop (max 3 attempts)
  6. On transient error, call ProviderFallbackPlugin and retry
  7. Extract tokens/cost from result metadata
  8. Call CostTrackingPlugin to persist log
  9. Map to ChatResponse
- [ ] Tracks total elapsed time with Stopwatch
- [ ] Throws `AllProvidersFailedException` after 3 failed attempts
- [ ] `IsTransientError()` helper checks: 429, 500-504, HttpRequestException, TaskCanceledException

### ✅ Criterion 8: In-Memory Repository Implementations
- [ ] `InMemoryRequestLogRepository` with List<RequestLog> storage
- [ ] `InMemoryModelPricingRepository` with pre-seeded pricing data
- [ ] Both implement respective interfaces from Domain layer
- [ ] Used for testing only (in Tests project)

### ✅ Criterion 9: Unit Tests Pass
- [ ] ModelSelectionPlugin: 5+ tests (user override, large context, default, token limit exceeded)
- [ ] ProviderFallbackPlugin: 3+ tests (each fallback step, cycle detection)
- [ ] CostTrackingPlugin: 3+ tests (successful tracking, missing pricing, repository called)
- [ ] Command validation: 3+ tests (empty messages, invalid temperature, invalid maxTokens)
- [ ] All tests use FluentAssertions and Moq
- [ ] Tests run in isolation (no shared state)

### ✅ Criterion 10: Integration Tests Pass
- [ ] Orchestrator test with real Kernel + in-memory repos
- [ ] Verifies plugin invocation sequence
- [ ] Tests successful completion flow
- [ ] Tests fallback retry logic
- [ ] Uses mock IChatCompletionService (Infrastructure not yet implemented)

### ✅ Criterion 11: Application Layer Has Correct Dependencies
- [ ] References Domain project only
- [ ] NuGet packages: Microsoft.SemanticKernel, Microsoft.Extensions.Logging
- [ ] No references to Infrastructure or API projects

---

## Prerequisites

**Completed:**
- ✅ US-001: Project structure created
- ✅ US-002: Domain layer implemented

**Required Knowledge:**
- Semantic Kernel plugin pattern
- Manual orchestration vs auto-function-calling
- Async/await with CancellationToken
- Constructor injection and DI patterns

---

## Step-by-Step Implementation

### Step 1: Create DTOs (10 minutes)

**Create folder**: `src/LLMGateway.Application/DTOs/`

**Delete default Class1.cs**:
```bash
rm src/LLMGateway.Application/Class1.cs
```

**File**: `src/LLMGateway.Application/DTOs/Message.cs`

```csharp
namespace LLMGateway.Application.DTOs;

public class Message
{
    public string Role { get; set; } = string.Empty;
    public string Content { get; set; } = string.Empty;
}
```

**File**: `src/LLMGateway.Application/DTOs/ChatRequest.cs`

```csharp
namespace LLMGateway.Application.DTOs;

public class ChatRequest
{
    public IEnumerable<Message> Messages { get; set; } = Enumerable.Empty<Message>();
    public string? Model { get; set; }
    public decimal? Temperature { get; set; }
    public int? MaxTokens { get; set; }
}
```

**File**: `src/LLMGateway.Application/DTOs/ChatResponse.cs`

```csharp
namespace LLMGateway.Application.DTOs;

public class ChatResponse
{
    public string Content { get; set; } = string.Empty;
    public string Model { get; set; } = string.Empty;
    public int TokensUsed { get; set; }
    public decimal EstimatedCostUsd { get; set; }
    public TimeSpan ResponseTime { get; set; }
}
```

---

### Step 2: Create SendChatCompletionCommand (10 minutes)

**Create folder**: `src/LLMGateway.Application/Commands/`

**File**: `src/LLMGateway.Application/Commands/SendChatCompletionCommand.cs`

```csharp
using LLMGateway.Application.DTOs;

namespace LLMGateway.Application.Commands;

public record SendChatCompletionCommand(
    IEnumerable<Message> Messages,
    string? Model = null,
    decimal? Temperature = null,
    int? MaxTokens = null)
{
    public void Validate()
    {
        if (Messages == null || !Messages.Any())
            throw new ArgumentException("Messages cannot be empty", nameof(Messages));
        
        if (Messages.Any(m => string.IsNullOrWhiteSpace(m.Content)))
            throw new ArgumentException("Message content cannot be empty", nameof(Messages));
        
        if (Temperature.HasValue && (Temperature < 0 || Temperature > 2))
            throw new ArgumentException(
                "Temperature must be between 0 and 2", 
                nameof(Temperature));
        
        if (MaxTokens.HasValue && MaxTokens <= 0)
            throw new ArgumentException(
                "MaxTokens must be positive", 
                nameof(MaxTokens));
    }
}
```

---

### Step 3: Implement ModelSelectionPlugin (15 minutes)

**Create folder**: `src/LLMGateway.Application/Plugins/`

**File**: `src/LLMGateway.Application/Plugins/ModelSelectionPlugin.cs`

```csharp
using LLMGateway.Domain.Constants;
using LLMGateway.Domain.Exceptions;
using LLMGateway.Domain.ValueObjects;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;

namespace LLMGateway.Application.Plugins;

public class ModelSelectionPlugin
{
    private readonly ILogger<ModelSelectionPlugin> _logger;
    
    public ModelSelectionPlugin(ILogger<ModelSelectionPlugin> logger)
    {
        _logger = logger;
    }
    
    [KernelFunction("select_model")]
    [Description("Selects the appropriate model based on token count and user preference")]
    public Task<string> SelectModelAsync(
        [Description("Estimated token count for the request")] int tokenCount,
        [Description("User-specified model (optional)")] string? userModel)
    {
        // Validate token limit
        if (tokenCount > ModelDefaults.LargeContextLimit)
        {
            _logger.LogWarning(
                "Token count {TokenCount} exceeds maximum limit {MaxLimit}",
                tokenCount,
                ModelDefaults.LargeContextLimit);
            
            throw new TokenLimitExceededException(
                TokenCount.From(tokenCount),
                ModelDefaults.LargeContextLimit);
        }
        
        // Rule 1: User-specified model takes precedence
        if (!string.IsNullOrWhiteSpace(userModel))
        {
            _logger.LogInformation(
                "Using user-specified model: {Model}",
                userModel);
            return Task.FromResult(userModel);
        }
        
        // Rule 2: Large context detection
        if (tokenCount > ModelDefaults.StandardContextLimit)
        {
            _logger.LogInformation(
                "Token count {TokenCount} exceeds standard limit, selecting large context model: {Model}",
                tokenCount,
                ModelDefaults.LargeContextModel);
            return Task.FromResult(ModelDefaults.LargeContextModel);
        }
        
        // Rule 3: Default to fast/cheap model
        _logger.LogInformation(
            "Using default model for {TokenCount} tokens: {Model}",
            tokenCount,
            ModelDefaults.DefaultModel);
        return Task.FromResult(ModelDefaults.DefaultModel);
    }
}
```

---

### Step 4: Implement ProviderFallbackPlugin (15 minutes)

**File**: `src/LLMGateway.Application/Plugins/ProviderFallbackPlugin.cs`

```csharp
using LLMGateway.Domain.Constants;
using LLMGateway.Domain.Exceptions;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;

namespace LLMGateway.Application.Plugins;

public class ProviderFallbackPlugin
{
    private readonly ILogger<ProviderFallbackPlugin> _logger;
    
    public ProviderFallbackPlugin(ILogger<ProviderFallbackPlugin> logger)
    {
        _logger = logger;
    }
    
    [KernelFunction("get_fallback_model")]
    [Description("Gets the next model in the fallback chain after a failure")]
    public Task<string> GetFallbackModelAsync(
        [Description("The model that failed")] string failedModel)
    {
        var fallbackChain = ModelDefaults.FallbackChain;
        var currentIndex = Array.IndexOf(fallbackChain, failedModel);
        
        // Model not in chain or reached end of chain
        if (currentIndex == -1 || currentIndex >= fallbackChain.Length - 1)
        {
            _logger.LogError(
                "All providers failed. Attempted models: {Models}",
                string.Join(", ", fallbackChain));
            
            throw new AllProvidersFailedException(fallbackChain);
        }
        
        var nextModel = fallbackChain[currentIndex + 1];
        
        _logger.LogWarning(
            "Falling back from {FailedModel} to {NextModel}",
            failedModel,
            nextModel);
        
        return Task.FromResult(nextModel);
    }
}
```

---

### Step 5: Implement CostTrackingPlugin (20 minutes)

**File**: `src/LLMGateway.Application/Plugins/CostTrackingPlugin.cs`

```csharp
using LLMGateway.Domain.Entities;
using LLMGateway.Domain.Interfaces;
using LLMGateway.Domain.ValueObjects;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;

namespace LLMGateway.Application.Plugins;

public class CostTrackingPlugin
{
    private readonly IRequestLogRepository _logRepository;
    private readonly IModelPricingRepository _pricingRepository;
    private readonly ILogger<CostTrackingPlugin> _logger;
    
    public CostTrackingPlugin(
        IRequestLogRepository logRepository,
        IModelPricingRepository pricingRepository,
        ILogger<CostTrackingPlugin> logger)
    {
        _logRepository = logRepository;
        _pricingRepository = pricingRepository;
        _logger = logger;
    }
    
    [KernelFunction("track_cost")]
    [Description("Tracks the cost and details of a completed request")]
    public async Task TrackCostAsync(
        [Description("Model used for the request")] string modelName,
        [Description("Number of input tokens")] int inputTokens,
        [Description("Number of output tokens")] int outputTokens,
        [Description("Provider name (e.g., OpenRouter)")] string providerName,
        [Description("Response time in milliseconds")] long responseTimeMs,
        [Description("Whether fallback was used")] bool wasFallback,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var model = ModelName.From(modelName);
            var inputTokenCount = TokenCount.From(inputTokens);
            var outputTokenCount = TokenCount.From(outputTokens);
            
            // Fetch pricing information
            var pricing = await _pricingRepository.GetByModelAsync(model, cancellationToken);
            
            CostAmount cost;
            if (pricing == null)
            {
                _logger.LogWarning(
                    "No pricing information found for model {Model}. Using zero cost.",
                    modelName);
                cost = CostAmount.Zero;
            }
            else
            {
                cost = pricing.CalculateCost(inputTokenCount, outputTokenCount);
            }
            
            // Create and persist request log
            var log = RequestLog.Create(
                model,
                inputTokenCount,
                outputTokenCount,
                cost,
                providerName,
                TimeSpan.FromMilliseconds(responseTimeMs),
                wasFallback);
            
            await _logRepository.SaveAsync(log, cancellationToken);
            
            _logger.LogInformation(
                "Tracked request: Model={Model}, Tokens={Tokens}, Cost={Cost:F6}, Fallback={Fallback}",
                modelName,
                inputTokens + outputTokens,
                cost.ValueUsd,
                wasFallback);
        }
        catch (Exception ex)
        {
            _logger.LogError(
                ex,
                "Failed to track cost for model {Model}",
                modelName);
            // Don't throw - cost tracking failure shouldn't break the response
        }
    }
}
```

---

### Step 6: Implement KernelFactory (15 minutes)

**Create folder**: `src/LLMGateway.Application/Orchestration/`

**File**: `src/LLMGateway.Application/Orchestration/KernelFactory.cs`

```csharp
using LLMGateway.Application.Plugins;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;

namespace LLMGateway.Application.Orchestration;

public class KernelFactory
{
    private readonly IServiceProvider _serviceProvider;
    
    public KernelFactory(IServiceProvider serviceProvider)
    {
        _serviceProvider = serviceProvider;
    }
    
    public Kernel CreateWithPlugins()
    {
        var builder = Kernel.CreateBuilder();
        
        // Register chat completion service from DI
        var chatCompletionService = _serviceProvider.GetRequiredService<IChatCompletionService>();
        builder.Services.AddSingleton(chatCompletionService);
        
        // Register plugins from DI (with resolved dependencies)
        var modelSelection = _serviceProvider.GetRequiredService<ModelSelectionPlugin>();
        builder.Plugins.AddFromObject(modelSelection, pluginName: "ModelSelection");
        
        var costTracking = _serviceProvider.GetRequiredService<CostTrackingPlugin>();
        builder.Plugins.AddFromObject(costTracking, pluginName: "CostTracking");
        
        var providerFallback = _serviceProvider.GetRequiredService<ProviderFallbackPlugin>();
        builder.Plugins.AddFromObject(providerFallback, pluginName: "ProviderFallback");
        
        return builder.Build();
    }
}
```

---

### Step 7: Implement KernelOrchestrator (30 minutes)

**File**: `src/LLMGateway.Application/Orchestration/KernelOrchestrator.cs`

```csharp
using System.Diagnostics;
using System.Net;
using LLMGateway.Application.Commands;
using LLMGateway.Application.DTOs;
using LLMGateway.Application.Plugins;
using LLMGateway.Domain.Exceptions;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;

namespace LLMGateway.Application.Orchestration;

public class KernelOrchestrator
{
    private readonly KernelFactory _kernelFactory;
    private readonly ModelSelectionPlugin _modelSelection;
    private readonly CostTrackingPlugin _costTracking;
    private readonly ProviderFallbackPlugin _providerFallback;
    private readonly ILogger<KernelOrchestrator> _logger;
    
    public KernelOrchestrator(
        KernelFactory kernelFactory,
        ModelSelectionPlugin modelSelection,
        CostTrackingPlugin costTracking,
        ProviderFallbackPlugin providerFallback,
        ILogger<KernelOrchestrator> logger)
    {
        _kernelFactory = kernelFactory;
        _modelSelection = modelSelection;
        _costTracking = costTracking;
        _providerFallback = providerFallback;
        _logger = logger;
    }
    
    public async Task<ChatResponse> SendChatCompletionAsync(
        SendChatCompletionCommand command,
        CancellationToken cancellationToken = default)
    {
        var stopwatch = Stopwatch.StartNew();
        
        try
        {
            // Validate command
            command.Validate();
            
            var kernel = _kernelFactory.CreateWithPlugins();
            
            // Step 1: Estimate tokens and select model
            var estimatedTokens = EstimateTokens(command.Messages);
            var selectedModel = await _modelSelection.SelectModelAsync(
                estimatedTokens,
                command.Model);
            
            // Step 2: Call completion service with retry/fallback
            var (result, finalModel, attempts) = await ExecuteWithFallbackAsync(
                kernel,
                command,
                selectedModel,
                cancellationToken);
            
            stopwatch.Stop();
            
            // Step 3: Extract metadata and track cost
            var inputTokens = ExtractInputTokens(result);
            var outputTokens = ExtractOutputTokens(result);
            
            await _costTracking.TrackCostAsync(
                finalModel,
                inputTokens,
                outputTokens,
                "OpenRouter",
                stopwatch.ElapsedMilliseconds,
                wasFallback: attempts > 1,
                cancellationToken);
            
            // Step 4: Map to response
            return new ChatResponse
            {
                Content = result.Content ?? string.Empty,
                Model = finalModel,
                TokensUsed = inputTokens + outputTokens,
                EstimatedCostUsd = 0m, // Will be calculated in Infrastructure layer
                ResponseTime = stopwatch.Elapsed
            };
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to complete chat request");
            throw;
        }
    }
    
    private async Task<(ChatMessageContent result, string model, int attempts)> ExecuteWithFallbackAsync(
        Kernel kernel,
        SendChatCompletionCommand command,
        string initialModel,
        CancellationToken cancellationToken)
    {
        var currentModel = initialModel;
        var attempts = 0;
        var maxAttempts = 3;
        
        while (attempts < maxAttempts)
        {
            attempts++;
            
            try
            {
                var chatHistory = BuildChatHistory(command.Messages);
                var completionService = kernel.GetRequiredService<IChatCompletionService>();
                
                var executionSettings = new PromptExecutionSettings
                {
                    ModelId = currentModel,
                    ExtensionData = new Dictionary<string, object>
                    {
                        ["temperature"] = (double)(command.Temperature ?? 0.7m),
                        ["max_tokens"] = command.MaxTokens ?? 2000
                    }
                };
                
                var results = await completionService.GetChatMessageContentsAsync(
                    chatHistory,
                    executionSettings,
                    kernel,
                    cancellationToken);
                
                return (results.First(), currentModel, attempts);
            }
            catch (Exception ex) when (IsTransientError(ex) && attempts < maxAttempts)
            {
                _logger.LogWarning(
                    ex,
                    "Transient error on attempt {Attempt}/{MaxAttempts} for model {Model}",
                    attempts,
                    maxAttempts,
                    currentModel);
                
                // Get fallback model
                currentModel = await _providerFallback.GetFallbackModelAsync(currentModel);
            }
        }
        
        throw new AllProvidersFailedException(new[] { initialModel });
    }
    
    private bool IsTransientError(Exception ex)
    {
        return ex switch
        {
            HttpRequestException httpEx =>
                httpEx.StatusCode == HttpStatusCode.TooManyRequests ||
                (int?)httpEx.StatusCode >= 500,
            
            TaskCanceledException => true,
            
            _ => false
        };
    }
    
    private int EstimateTokens(IEnumerable<Message> messages)
    {
        var totalChars = messages.Sum(m => m.Content.Length);
        return totalChars / 4; // Simple estimation: ~4 chars per token
    }
    
    private ChatHistory BuildChatHistory(IEnumerable<Message> messages)
    {
        var chatHistory = new ChatHistory();
        
        foreach (var message in messages)
        {
            chatHistory.AddMessage(
                new AuthorRole(message.Role),
                message.Content);
        }
        
        return chatHistory;
    }
    
    private int ExtractInputTokens(ChatMessageContent result)
    {
        // Try to extract from metadata if available
        if (result.Metadata?.TryGetValue("input_tokens", out var inputTokens) == true)
        {
            return Convert.ToInt32(inputTokens);
        }
        
        // Fallback: estimate from result (will be more accurate in Infrastructure layer)
        return 0;
    }
    
    private int ExtractOutputTokens(ChatMessageContent result)
    {
        // Try to extract from metadata if available
        if (result.Metadata?.TryGetValue("output_tokens", out var outputTokens) == true)
        {
            return Convert.ToInt32(outputTokens);
        }
        
        // Fallback: estimate from content
        return (result.Content?.Length ?? 0) / 4;
    }
}
```

---

### Step 8: Create In-Memory Repositories for Testing (15 minutes)

**Create folder**: `tests/LLMGateway.Application.Tests/TestDoubles/`

**Delete default test file**:
```bash
rm tests/LLMGateway.Application.Tests/UnitTest1.cs
```

**File**: `tests/LLMGateway.Application.Tests/TestDoubles/InMemoryRequestLogRepository.cs`

```csharp
using LLMGateway.Domain.Entities;
using LLMGateway.Domain.Interfaces;
using LLMGateway.Domain.ValueObjects;

namespace LLMGateway.Application.Tests.TestDoubles;

public class InMemoryRequestLogRepository : IRequestLogRepository
{
    private readonly List<RequestLog> _logs = new();
    
    public Task<RequestLog> SaveAsync(
        RequestLog log,
        CancellationToken cancellationToken = default)
    {
        _logs.Add(log);
        return Task.FromResult(log);
    }
    
    public Task<IEnumerable<RequestLog>> GetRecentAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return Task.FromResult(
            _logs.OrderByDescending(x => x.Timestamp)
                 .Take(count)
                 .AsEnumerable());
    }
    
    public Task<CostAmount> GetTotalCostAsync(
        DateTime since,
        CancellationToken cancellationToken = default)
    {
        var total = _logs
            .Where(x => x.Timestamp >= since)
            .Select(x => x.EstimatedCost)
            .Aggregate(CostAmount.Zero, (acc, cost) => acc.Add(cost));
        
        return Task.FromResult(total);
    }
}
```

**File**: `tests/LLMGateway.Application.Tests/TestDoubles/InMemoryModelPricingRepository.cs`

```csharp
using LLMGateway.Domain.Constants;
using LLMGateway.Domain.Entities;
using LLMGateway.Domain.Interfaces;
using LLMGateway.Domain.ValueObjects;

namespace LLMGateway.Application.Tests.TestDoubles;

public class InMemoryModelPricingRepository : IModelPricingRepository
{
    private readonly List<ModelPricing> _pricing;
    
    public InMemoryModelPricingRepository()
    {
        // Seed with default pricing data
        _pricing = new List<ModelPricing>
        {
            ModelPricing.Create(
                ModelName.From(ModelDefaults.DefaultModel),
                "z-ai",
                inputCost: 0.0001m,
                outputCost: 0.0002m,
                maxTokens: 128_000),
            
            ModelPricing.Create(
                ModelName.From(ModelDefaults.BalancedModel),
                "deepseek-ai",
                inputCost: 0.0003m,
                outputCost: 0.0005m,
                maxTokens: 64_000),
            
            ModelPricing.Create(
                ModelName.From(ModelDefaults.LargeContextModel),
                "moonshotai",
                inputCost: 0.0005m,
                outputCost: 0.0010m,
                maxTokens: 200_000)
        };
    }
    
    public Task<ModelPricing?> GetByModelAsync(
        ModelName model,
        CancellationToken cancellationToken = default)
    {
        var pricing = _pricing.FirstOrDefault(p => p.Model == model);
        return Task.FromResult(pricing);
    }
    
    public Task<IEnumerable<ModelPricing>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return Task.FromResult(_pricing.AsEnumerable());
    }
}
```

---

### Step 9: Write Unit Tests for Plugins (30 minutes)

**Create folder**: `tests/LLMGateway.Application.Tests/Plugins/`

**File**: `tests/LLMGateway.Application.Tests/Plugins/ModelSelectionPluginTests.cs`

```csharp
using FluentAssertions;
using LLMGateway.Application.Plugins;
using LLMGateway.Domain.Constants;
using LLMGateway.Domain.Exceptions;
using Microsoft.Extensions.Logging;
using Moq;

namespace LLMGateway.Application.Tests.Plugins;

public class ModelSelectionPluginTests
{
    private readonly ModelSelectionPlugin _plugin;
    
    public ModelSelectionPluginTests()
    {
        var mockLogger = new Mock<ILogger<ModelSelectionPlugin>>();
        _plugin = new ModelSelectionPlugin(mockLogger.Object);
    }
    
    [Fact]
    public async Task SelectModel_UserSpecifiedModel_ReturnsUserModel()
    {
        // Arrange
        var userModel = "custom-model/test";
        
        // Act
        var result = await _plugin.SelectModelAsync(5000, userModel);
        
        // Assert
        result.Should().Be(userModel);
    }
    
    [Fact]
    public async Task SelectModel_LargeContext_ReturnsKimiModel()
    {
        // Arrange
        var tokenCount = 15000; // Exceeds StandardContextLimit (10,000)
        
        // Act
        var result = await _plugin.SelectModelAsync(tokenCount, null);
        
        // Assert
        result.Should().Be(ModelDefaults.LargeContextModel);
    }
    
    [Fact]
    public async Task SelectModel_StandardContext_ReturnsDefaultModel()
    {
        // Arrange
        var tokenCount = 5000; // Below StandardContextLimit
        
        // Act
        var result = await _plugin.SelectModelAsync(tokenCount, null);
        
        // Assert
        result.Should().Be(ModelDefaults.DefaultModel);
    }
    
    [Fact]
    public async Task SelectModel_ExceedsMaxLimit_ThrowsTokenLimitExceededException()
    {
        // Arrange
        var tokenCount = 250000; // Exceeds LargeContextLimit (200,000)
        
        // Act
        var act = () => _plugin.SelectModelAsync(tokenCount, null);
        
        // Assert
        await act.Should().ThrowAsync<TokenLimitExceededException>()
            .WithMessage("*exceeds limit*");
    }
    
    [Fact]
    public async Task SelectModel_AtStandardLimit_ReturnsDefaultModel()
    {
        // Arrange
        var tokenCount = ModelDefaults.StandardContextLimit; // Exactly at limit
        
        // Act
        var result = await _plugin.SelectModelAsync(tokenCount, null);
        
        // Assert
        result.Should().Be(ModelDefaults.DefaultModel);
    }
}
```

**File**: `tests/LLMGateway.Application.Tests/Plugins/ProviderFallbackPluginTests.cs`

```csharp
using FluentAssertions;
using LLMGateway.Application.Plugins;
using LLMGateway.Domain.Constants;
using LLMGateway.Domain.Exceptions;
using Microsoft.Extensions.Logging;
using Moq;

namespace LLMGateway.Application.Tests.Plugins;

public class ProviderFallbackPluginTests
{
    private readonly ProviderFallbackPlugin _plugin;
    
    public ProviderFallbackPluginTests()
    {
        var mockLogger = new Mock<ILogger<ProviderFallbackPlugin>>();
        _plugin = new ProviderFallbackPlugin(mockLogger.Object);
    }
    
    [Fact]
    public async Task GetFallbackModel_DefaultModelFails_ReturnsBalancedModel()
    {
        // Act
        var result = await _plugin.GetFallbackModelAsync(ModelDefaults.DefaultModel);
        
        // Assert
        result.Should().Be(ModelDefaults.BalancedModel);
    }
    
    [Fact]
    public async Task GetFallbackModel_BalancedModelFails_ReturnsLargeContextModel()
    {
        // Act
        var result = await _plugin.GetFallbackModelAsync(ModelDefaults.BalancedModel);
        
        // Assert
        result.Should().Be(ModelDefaults.LargeContextModel);
    }
    
    [Fact]
    public async Task GetFallbackModel_AllModelsFailed_ThrowsAllProvidersFailedException()
    {
        // Act
        var act = () => _plugin.GetFallbackModelAsync(ModelDefaults.LargeContextModel);
        
        // Assert
        await act.Should().ThrowAsync<AllProvidersFailedException>()
            .WithMessage("*All providers failed*");
    }
    
    [Fact]
    public async Task GetFallbackModel_UnknownModel_ThrowsAllProvidersFailedException()
    {
        // Act
        var act = () => _plugin.GetFallbackModelAsync("unknown-model");
        
        // Assert
        await act.Should().ThrowAsync<AllProvidersFailedException>();
    }
}
```

**File**: `tests/LLMGateway.Application.Tests/Plugins/CostTrackingPluginTests.cs`

```csharp
using FluentAssertions;
using LLMGateway.Application.Plugins;
using LLMGateway.Application.Tests.TestDoubles;
using LLMGateway.Domain.Constants;
using LLMGateway.Domain.Entities;
using LLMGateway.Domain.Interfaces;
using Microsoft.Extensions.Logging;
using Moq;

namespace LLMGateway.Application.Tests.Plugins;

public class CostTrackingPluginTests
{
    private readonly InMemoryRequestLogRepository _logRepository;
    private readonly InMemoryModelPricingRepository _pricingRepository;
    private readonly CostTrackingPlugin _plugin;
    
    public CostTrackingPluginTests()
    {
        _logRepository = new InMemoryRequestLogRepository();
        _pricingRepository = new InMemoryModelPricingRepository();
        var mockLogger = new Mock<ILogger<CostTrackingPlugin>>();
        
        _plugin = new CostTrackingPlugin(
            _logRepository,
            _pricingRepository,
            mockLogger.Object);
    }
    
    [Fact]
    public async Task TrackCost_ValidRequest_PersistsLog()
    {
        // Arrange
        var modelName = ModelDefaults.DefaultModel;
        var inputTokens = 100;
        var outputTokens = 200;
        
        // Act
        await _plugin.TrackCostAsync(
            modelName,
            inputTokens,
            outputTokens,
            "OpenRouter",
            1234,
            wasFallback: false);
        
        // Assert
        var logs = await _logRepository.GetRecentAsync(10);
        logs.Should().HaveCount(1);
        
        var log = logs.First();
        log.ModelUsed.Value.Should().Be(modelName);
        log.InputTokens.Value.Should().Be(inputTokens);
        log.OutputTokens.Value.Should().Be(outputTokens);
        log.ProviderName.Should().Be("OpenRouter");
        log.WasFallback.Should().BeFalse();
    }
    
    [Fact]
    public async Task TrackCost_CalculatesCostCorrectly()
    {
        // Arrange
        var modelName = ModelDefaults.DefaultModel;
        var inputTokens = 1_000_000; // 1M tokens
        var outputTokens = 1_000_000; // 1M tokens
        
        // Expected: (1M / 1M) * 0.0001 + (1M / 1M) * 0.0002 = 0.0003
        
        // Act
        await _plugin.TrackCostAsync(
            modelName,
            inputTokens,
            outputTokens,
            "OpenRouter",
            1000,
            wasFallback: false);
        
        // Assert
        var logs = await _logRepository.GetRecentAsync(1);
        var log = logs.First();
        log.EstimatedCost.ValueUsd.Should().Be(0.0003m);
    }
    
    [Fact]
    public async Task TrackCost_MissingPricing_UsesZeroCost()
    {
        // Arrange
        var unknownModel = "unknown/model";
        
        // Act
        await _plugin.TrackCostAsync(
            unknownModel,
            100,
            200,
            "OpenRouter",
            1000,
            wasFallback: false);
        
        // Assert
        var logs = await _logRepository.GetRecentAsync(1);
        var log = logs.First();
        log.EstimatedCost.ValueUsd.Should().Be(0m);
    }
    
    [Fact]
    public async Task TrackCost_WithFallback_SetsFlagCorrectly()
    {
        // Act
        await _plugin.TrackCostAsync(
            ModelDefaults.BalancedModel,
            50,
            150,
            "OpenRouter",
            2000,
            wasFallback: true);
        
        // Assert
        var logs = await _logRepository.GetRecentAsync(1);
        logs.First().WasFallback.Should().BeTrue();
    }
}
```

---

### Step 10: Write Command Validation Tests (10 minutes)

**Create folder**: `tests/LLMGateway.Application.Tests/Commands/`

**File**: `tests/LLMGateway.Application.Tests/Commands/SendChatCompletionCommandTests.cs`

```csharp
using FluentAssertions;
using LLMGateway.Application.Commands;
using LLMGateway.Application.DTOs;

namespace LLMGateway.Application.Tests.Commands;

public class SendChatCompletionCommandTests
{
    [Fact]
    public void Validate_ValidCommand_DoesNotThrow()
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: new[]
            {
                new Message { Role = "user", Content = "Hello" }
            });
        
        // Act
        var act = () => command.Validate();
        
        // Assert
        act.Should().NotThrow();
    }
    
    [Fact]
    public void Validate_EmptyMessages_ThrowsArgumentException()
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: Enumerable.Empty<Message>());
        
        // Act
        var act = () => command.Validate();
        
        // Assert
        act.Should().Throw<ArgumentException>()
            .WithMessage("*Messages cannot be empty*");
    }
    
    [Fact]
    public void Validate_EmptyMessageContent_ThrowsArgumentException()
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: new[]
            {
                new Message { Role = "user", Content = "" }
            });
        
        // Act
        var act = () => command.Validate();
        
        // Assert
        act.Should().Throw<ArgumentException>()
            .WithMessage("*content cannot be empty*");
    }
    
    [Theory]
    [InlineData(-0.1)]
    [InlineData(2.1)]
    [InlineData(5.0)]
    public void Validate_InvalidTemperature_ThrowsArgumentException(decimal temperature)
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: new[]
            {
                new Message { Role = "user", Content = "Hello" }
            },
            Temperature: temperature);
        
        // Act
        var act = () => command.Validate();
        
        // Assert
        act.Should().Throw<ArgumentException>()
            .WithMessage("*Temperature must be between 0 and 2*");
    }
    
    [Theory]
    [InlineData(0)]
    [InlineData(-1)]
    [InlineData(-100)]
    public void Validate_InvalidMaxTokens_ThrowsArgumentException(int maxTokens)
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: new[]
            {
                new Message { Role = "user", Content = "Hello" }
            },
            MaxTokens: maxTokens);
        
        // Act
        var act = () => command.Validate();
        
        // Assert
        act.Should().Throw<ArgumentException>()
            .WithMessage("*MaxTokens must be positive*");
    }
    
    [Theory]
    [InlineData(0)]
    [InlineData(0.7)]
    [InlineData(1.5)]
    [InlineData(2.0)]
    public void Validate_ValidTemperature_DoesNotThrow(decimal temperature)
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: new[]
            {
                new Message { Role = "user", Content = "Hello" }
            },
            Temperature: temperature);
        
        // Act
        var act = () => command.Validate();
        
        // Assert
        act.Should().NotThrow();
    }
}
```

---

### Step 11: Write Integration Tests for Orchestrator (20 minutes)

**Create folder**: `tests/LLMGateway.Application.Tests/Orchestration/`

**File**: `tests/LLMGateway.Application.Tests/Orchestration/KernelOrchestratorTests.cs`

```csharp
using FluentAssertions;
using LLMGateway.Application.Commands;
using LLMGateway.Application.DTOs;
using LLMGateway.Application.Orchestration;
using LLMGateway.Application.Plugins;
using LLMGateway.Application.Tests.TestDoubles;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Moq;

namespace LLMGateway.Application.Tests.Orchestration;

public class KernelOrchestratorTests
{
    private readonly Mock<IChatCompletionService> _mockCompletionService;
    private readonly KernelOrchestrator _orchestrator;
    
    public KernelOrchestratorTests()
    {
        // Setup in-memory repositories
        var logRepository = new InMemoryRequestLogRepository();
        var pricingRepository = new InMemoryModelPricingRepository();
        
        // Setup mock completion service
        _mockCompletionService = new Mock<IChatCompletionService>();
        
        // Setup DI container
        var services = new ServiceCollection();
        services.AddLogging();
        services.AddSingleton(_mockCompletionService.Object);
        services.AddSingleton(logRepository);
        services.AddSingleton(pricingRepository);
        services.AddSingleton<ModelSelectionPlugin>();
        services.AddSingleton<CostTrackingPlugin>();
        services.AddSingleton<ProviderFallbackPlugin>();
        services.AddSingleton<KernelFactory>();
        
        var serviceProvider = services.BuildServiceProvider();
        
        // Create orchestrator
        var factory = serviceProvider.GetRequiredService<KernelFactory>();
        var modelSelection = serviceProvider.GetRequiredService<ModelSelectionPlugin>();
        var costTracking = serviceProvider.GetRequiredService<CostTrackingPlugin>();
        var providerFallback = serviceProvider.GetRequiredService<ProviderFallbackPlugin>();
        var logger = serviceProvider.GetRequiredService<ILogger<KernelOrchestrator>>();
        
        _orchestrator = new KernelOrchestrator(
            factory,
            modelSelection,
            costTracking,
            providerFallback,
            logger);
    }
    
    [Fact]
    public async Task SendChatCompletion_ValidRequest_ReturnsResponse()
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: new[]
            {
                new Message { Role = "user", Content = "Hello, world!" }
            });
        
        var mockResult = new ChatMessageContent(
            AuthorRole.Assistant,
            "Hello! How can I help you?");
        
        _mockCompletionService
            .Setup(x => x.GetChatMessageContentsAsync(
                It.IsAny<ChatHistory>(),
                It.IsAny<PromptExecutionSettings>(),
                It.IsAny<Kernel>(),
                It.IsAny<CancellationToken>()))
            .ReturnsAsync(new List<ChatMessageContent> { mockResult });
        
        // Act
        var response = await _orchestrator.SendChatCompletionAsync(command);
        
        // Assert
        response.Should().NotBeNull();
        response.Content.Should().Be("Hello! How can I help you?");
        response.Model.Should().NotBeNullOrEmpty();
        response.ResponseTime.Should().BeGreaterThan(TimeSpan.Zero);
    }
    
    [Fact]
    public async Task SendChatCompletion_InvalidCommand_ThrowsArgumentException()
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: Enumerable.Empty<Message>());
        
        // Act
        var act = () => _orchestrator.SendChatCompletionAsync(command);
        
        // Assert
        await act.Should().ThrowAsync<ArgumentException>();
    }
    
    [Fact]
    public async Task SendChatCompletion_CallsCompletionServiceWithCorrectSettings()
    {
        // Arrange
        var command = new SendChatCompletionCommand(
            Messages: new[]
            {
                new Message { Role = "user", Content = "Test" }
            },
            Temperature: 0.9m,
            MaxTokens: 500);
        
        var mockResult = new ChatMessageContent(
            AuthorRole.Assistant,
            "Response");
        
        _mockCompletionService
            .Setup(x => x.GetChatMessageContentsAsync(
                It.IsAny<ChatHistory>(),
                It.IsAny<PromptExecutionSettings>(),
                It.IsAny<Kernel>(),
                It.IsAny<CancellationToken>()))
            .ReturnsAsync(new List<ChatMessageContent> { mockResult });
        
        // Act
        await _orchestrator.SendChatCompletionAsync(command);
        
        // Assert
        _mockCompletionService.Verify(
            x => x.GetChatMessageContentsAsync(
                It.Is<ChatHistory>(h => h.Count == 1),
                It.Is<PromptExecutionSettings>(s =>
                    s.ExtensionData != null &&
                    (double)s.ExtensionData["temperature"] == 0.9 &&
                    (int)s.ExtensionData["max_tokens"] == 500),
                It.IsAny<Kernel>(),
                It.IsAny<CancellationToken>()),
            Times.Once);
    }
}
```

---

### Step 12: Add Required NuGet Packages (5 minutes)

```bash
# Add Semantic Kernel to Application project
dotnet add src/LLMGateway.Application package Microsoft.SemanticKernel

# Add required packages to test project
dotnet add tests/LLMGateway.Application.Tests package Moq
dotnet add tests/LLMGateway.Application.Tests package FluentAssertions
```

---

### Step 13: Add Project References (5 minutes)

```bash
# Application references Domain
dotnet add src/LLMGateway.Application reference src/LLMGateway.Domain

# Test project references Application and Domain
dotnet add tests/LLMGateway.Application.Tests reference src/LLMGateway.Application
dotnet add tests/LLMGateway.Application.Tests reference src/LLMGateway.Domain
```

---

### Step 14: Verify Build and Tests (5 minutes)

```bash
# Build Application project
dotnet build src/LLMGateway.Application

# Run Application tests
dotnet test tests/LLMGateway.Application.Tests --logger "console;verbosity=normal"

# Build entire solution
dotnet build

# Run all tests
dotnet test
```

---

### Step 15: Commit Changes (5 minutes)

```bash
# Stage all Application layer files
git add src/LLMGateway.Application/
git add tests/LLMGateway.Application.Tests/

# Commit with descriptive message
git commit -m "feat: Implement Application layer (US-003)

- Add DTOs (ChatRequest, ChatResponse, Message)
- Add SendChatCompletionCommand with validation
- Implement ModelSelectionPlugin with 3-rule routing
- Implement ProviderFallbackPlugin with circular fallback chain
- Implement CostTrackingPlugin with cost calculation and persistence
- Implement KernelFactory to configure SK with plugins
- Implement KernelOrchestrator with manual plugin invocation
- Add in-memory repository implementations for testing
- Add comprehensive unit tests for plugins and commands
- Add integration tests for orchestrator with real Kernel

Application layer uses manual plugin invocation (not SK auto-chaining)"

# Push to GitHub
git push
```

---

## Verification Steps

```bash
# 1. Application project builds with correct dependencies
dotnet build src/LLMGateway.Application
# Expected: Build succeeded, references only Domain + SK

# 2. Check Application project references
dotnet list src/LLMGateway.Application reference
# Expected: ../LLMGateway.Domain/LLMGateway.Domain.csproj

# 3. All application tests pass
dotnet test tests/LLMGateway.Application.Tests --logger "console;verbosity=detailed"
# Expected: Passed! - Failed: 0, Passed: 20+, Skipped: 0

# 4. Verify plugins have KernelFunction attributes
grep -r "KernelFunction" src/LLMGateway.Application/Plugins/
# Expected: 3 matches (one per plugin)

# 5. Solution still compiles
dotnet build
# Expected: Build succeeded (all projects)

# 6. Git status clean
git status
# Expected: nothing to commit, working tree clean
```

---

## Definition of Done

- [x] DTOs created with proper serialization support
- [x] SendChatCompletionCommand with Validate() method
- [x] ModelSelectionPlugin implements 3-rule routing from ADR-003
- [x] ProviderFallbackPlugin implements circular fallback chain
- [x] CostTrackingPlugin persists logs via repository
- [x] KernelFactory configures Kernel with DI-injected plugins
- [x] KernelOrchestrator manually invokes plugins in correct sequence
- [x] Retry loop handles transient errors with fallback
- [x] In-memory repositories for testing
- [x] 20+ unit tests pass (plugins, commands, orchestration)
- [x] Integration tests verify SK wiring
- [x] Application project references only Domain + SK
- [x] Code committed to GitHub

---

## File Structure After US-003

```
src/LLMGateway.Application/
├── Commands/
│   └── SendChatCompletionCommand.cs
├── DTOs/
│   ├── ChatRequest.cs
│   ├── ChatResponse.cs
│   └── Message.cs
├── Orchestration/
│   ├── KernelOrchestrator.cs
│   └── KernelFactory.cs
├── Plugins/
│   ├── ModelSelectionPlugin.cs
│   ├── CostTrackingPlugin.cs
│   └── ProviderFallbackPlugin.cs
└── LLMGateway.Application.csproj

tests/LLMGateway.Application.Tests/
├── Commands/
│   └── SendChatCompletionCommandTests.cs
├── Orchestration/
│   └── KernelOrchestratorTests.cs
├── Plugins/
│   ├── ModelSelectionPluginTests.cs
│   ├── ProviderFallbackPluginTests.cs
│   └── CostTrackingPluginTests.cs
├── TestDoubles/
│   ├── InMemoryRequestLogRepository.cs
│   └── InMemoryModelPricingRepository.cs
└── LLMGateway.Application.Tests.csproj
```

---

## Troubleshooting

**Issue: KernelFunction attribute not recognized**
```bash
# Ensure correct using statement
using Microsoft.SemanticKernel;

# Verify SK package installed
dotnet list src/LLMGateway.Application package | grep SemanticKernel
```

**Issue: IChatCompletionService not found in Kernel**
```csharp
// Ensure service registered in KernelFactory
builder.Services.AddSingleton(chatCompletionService);

// Get service with null check
var service = kernel.GetRequiredService<IChatCompletionService>();
```

**Issue: Integration tests fail with missing metadata**
```csharp
// Mock result must have metadata if you're extracting tokens
var mockResult = new ChatMessageContent(
    AuthorRole.Assistant,
    "Response")
{
    Metadata = new Dictionary<string, object?>
    {
        ["input_tokens"] = 10,
        ["output_tokens"] = 20
    }
};
```

**Issue: Circular reference in DI**
```csharp
// Ensure KernelFactory doesn't create cycles
// It should only pull services, not inject itself
public KernelFactory(IServiceProvider serviceProvider)
{
    _serviceProvider = serviceProvider; // OK
}
```

---

## Key Learnings

**Manual Orchestration Pattern:**
- More explicit control than SK auto-chaining
- Easier to debug and test
- Clear execution sequence
- Suitable for deterministic workflows

**Plugin Design:**
- Single responsibility per function
- Stateless (dependencies injected)
- Decorated with `[KernelFunction]`
- Return Task for async operations

**Testing Strategy:**
- Unit test plugins independently (fast, isolated)
- Integration test with real Kernel (verifies SK wiring)
- Use in-memory repositories (no database required)
- Mock IChatCompletionService (Infrastructure not yet implemented)

---

## Next Steps

Once US-003 is complete:
- **US-004:** Implement Infrastructure layer (OpenRouterChatCompletionService, EF Core repositories, Polly resilience)
- **US-005:** Implement API layer (ChatCompletionController, middleware, Program.cs)
- **US-006:** End-to-end integration testing with real OpenRouter API